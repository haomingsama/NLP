{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from bs4 import BeautifulSoup\n",
    "from future.utils import iteritems\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "stopwords = set([w.rstrip() for w in open('stopwords.txt','r')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_review = BeautifulSoup(open('sorted_data_acl/electronics/positive.review').read())\n",
    "negative_review = BeautifulSoup(open('sorted_data_acl/electronics/negative.review').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_review = positive_review.findAll('review_text')\n",
    "negative_review = negative_review.findAll('review_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.element.ResultSet'>\n",
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(type(positive_review))\n",
    "print(len(positive_review))\n",
    "print(len(negative_review))\n",
    "#Numpy 尽然可以对这个对象进行操作\n",
    "np.random.shuffle(positive_review)\n",
    "#这里positive和negative是一样的数量，如果遇到不平衡的数据记得要让其平衡\n",
    "positive_review = positive_review[:len(negative_review)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_tokenizer(s):\n",
    "    s= s.lower()\n",
    "    tokens = nltk.tokenize.word_tokenize(s)\n",
    "    tokens = [s for s in tokens if len(s)>2]\n",
    "    tokens = [wordnet_lemmatizer.lemmatize(t) for t in tokens]\n",
    "    tokens = [t for t in tokens if t not in stopwords]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index_map ={}\n",
    "current_index = 0\n",
    "#为了避免重复做tokenize的计算，将token储存到一个列表里\n",
    "positive_tokenized = []\n",
    "negative_tokenized = []\n",
    "orig_reviews = []\n",
    "\n",
    "\n",
    "# 从postivie_review中收集词汇\n",
    "for review in positive_review:\n",
    "    orig_reviews.append(review.text)\n",
    "    tokens = my_tokenizer(review.text)\n",
    "    positive_tokenized.append(tokens)\n",
    "    for token in tokens:\n",
    "        if token not in word_index_map:\n",
    "            word_index_map[token] = current_index\n",
    "            current_index +=1\n",
    "\n",
    "# 从negative_review中看看还有没有新的词汇            \n",
    "for review in negative_review:\n",
    "    orig_reviews.append(review.text)\n",
    "    tokens = my_tokenizer(review.text)\n",
    "    negative_tokenized.append(tokens)\n",
    "    for token in tokens:\n",
    "        if token not in word_index_map:\n",
    "            word_index_map[token] = current_index\n",
    "            current_index +=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_to_vector(tokens,label):\n",
    "    x = np.zeros(len(word_index_map)+1) #+1是给label留了一个column\n",
    "    for t in tokens:\n",
    "        i = word_index_map[t]\n",
    "        x[i] +=1\n",
    "    x = x/x.sum()\n",
    "    x[-1] = label\n",
    "    return x\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(positive_review)+len(negative_review)\n",
    "data = np.zeros((N,len(word_index_map)+1))\n",
    "\n",
    "i = 0\n",
    "for token in positive_tokenized:\n",
    "    xy = tokens_to_vector(token,1)\n",
    "    data[i,:]=xy\n",
    "    i+=1\n",
    "\n",
    "for token in negative_tokenized:\n",
    "    xy = tokens_to_vector(token,0)\n",
    "    data[i,:]=xy\n",
    "    i+=1\n",
    "orig_reviews, data = shuffle(orig_reviews, data)\n",
    "# np.random.shuffle(data)\n",
    "X = data[:,:-1]\n",
    "Y = data[:,-1]\n",
    "# last 100 rows will be test\n",
    "Xtrain = X[:-100,]\n",
    "Ytrain = Y[:-100,]\n",
    "Xtest = X[-100:,]\n",
    "Ytest = Y[-100:,]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.7778947368421053\n",
      "Test accuracy: 0.7\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(Xtrain, Ytrain)\n",
    "print(\"Train accuracy:\", model.score(Xtrain, Ytrain))\n",
    "print(\"Test accuracy:\", model.score(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wa -1.6079729883072436\n",
      "little 0.9985095949384788\n",
      "unit -0.6326406624014576\n",
      "easy 1.6788120712624794\n",
      "price 2.787781834531714\n",
      "you 0.988370599040214\n",
      "n't -2.1706587649623503\n",
      "doe -1.2584637787147264\n",
      "pretty 0.7990337063487584\n",
      "speaker 0.975021578594107\n",
      "sound 1.0607556572690178\n",
      "excellent 1.3364495464316088\n",
      "ha 0.7071380740735853\n",
      "'ve 0.7372887550046962\n",
      "perfect 0.9113495406111854\n",
      "time -0.7223822320587461\n",
      "highly 0.9496587712837982\n",
      "recommend 0.6314202134674785\n",
      "then -1.0137314693291324\n",
      "returned -0.8345610724079219\n",
      "hour -0.5550369943982171\n",
      "lot 0.7442232435617449\n",
      "memory 0.9578603642774107\n",
      "home 0.6181950917223367\n",
      "video 0.5158314510745707\n",
      "using 0.6117792859580113\n",
      "paper 0.5282658736616545\n",
      "support -0.8401463459541889\n",
      "buy -0.6638912400879797\n",
      "expected 0.5802297373285455\n",
      "bad -0.7938641031723082\n",
      "look 0.5455444552443207\n",
      "try -0.6723387685600332\n",
      "space 0.5546310200763749\n",
      "love 1.1952957642722026\n",
      "month -0.744126726701251\n",
      "cable 0.6380364134299532\n",
      "picture 0.5488048544631335\n",
      "item -1.193542795765836\n",
      "fast 0.9195149401592645\n",
      "bit 0.6148284014021287\n",
      "quality 1.4572432626052085\n",
      "value 0.5605896399264072\n",
      "tried -0.7381288634193454\n",
      "money -0.9246855395119451\n",
      "comfortable 0.6513874622651642\n",
      "company -0.5501868724370887\n",
      "week -0.738995736497402\n",
      "happy 0.6749639607463308\n",
      "customer -0.6386028676196972\n",
      "warranty -0.6311589083703372\n",
      "sent -0.5457606067280695\n",
      "static -0.5221047249675507\n",
      "terrible -0.5054429844050972\n",
      "return -1.2191130939751924\n",
      "poor -0.7915281266557364\n",
      "returning -0.5482597461029143\n",
      "refund -0.6502950512213759\n",
      "junk -0.5304617745778177\n",
      "waste -1.0082659858158904\n",
      "stopped -0.518521966798747\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "for word, index in iteritems(word_index_map):\n",
    "    weight = model.coef_[0][index]\n",
    "    if weight > threshold or weight < -threshold:\n",
    "        print(word, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check misclassified examples\n",
    "preds = model.predict(X)\n",
    "P =model.predict_proba(X)[:,1] # p(y = 1 | x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most wrong positive review (prob = 0.347095271461556, pred = 0.0):\n",
      "\n",
      "A device like this either works or it doesn't.  This one happens to work\n",
      "\n",
      "Most wrong negative review (prob = 0.5984894108598078, pred = 1.0):\n",
      "\n",
      "The Voice recorder meets all my expectations and more\n",
      "Easy to use, easy to transfer great results\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# since there are many, just print the \"most\" wrong samples\n",
    "minP_whenYis1 = 1\n",
    "maxP_whenYis0 = 0\n",
    "wrong_positive_review = None\n",
    "wrong_negative_review = None\n",
    "wrong_positive_prediction = None\n",
    "wrong_negative_prediction = None\n",
    "\n",
    "for i in range(N):\n",
    "    p = P[i]\n",
    "    y = Y[i]\n",
    "    if y == 1 and p < 0.5:\n",
    "        if p < minP_whenYis1:\n",
    "            wrong_positive_review = orig_reviews[i]\n",
    "            wrong_positive_prediction = preds[i]\n",
    "            minP_whenYis1 = p\n",
    "    elif y == 0 and p > 0.5:\n",
    "        if p > maxP_whenYis0:\n",
    "            wrong_negative_review = orig_reviews[i]\n",
    "            wrong_negative_prediction = preds[i]\n",
    "            maxP_whenYis0 = p\n",
    "\n",
    "print(\"Most wrong positive review (prob = %s, pred = %s):\" % (minP_whenYis1, wrong_positive_prediction))\n",
    "print(wrong_positive_review)\n",
    "print(\"Most wrong negative review (prob = %s, pred = %s):\" % (maxP_whenYis0, wrong_negative_prediction))\n",
    "print(wrong_negative_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.  Try different Classifier\n",
    "Here I tried Naive Bayes and AdaBoost which I havved been implemented in the spam detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8726315789473684\n",
      "Test accuracy: 0.77\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB()\n",
    "model.fit(Xtrain,Ytrain)\n",
    "print(\"Train accuracy:\", model.score(Xtrain, Ytrain))\n",
    "print(\"Test accuracy:\", model.score(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8178947368421052\n",
      "Test accuracy: 0.76\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "model =AdaBoostClassifier()\n",
    "model.fit(Xtrain,Ytrain)\n",
    "print(\"Train accuracy:\", model.score(Xtrain, Ytrain))\n",
    "print(\"Test accuracy:\", model.score(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Use different feature\n",
    "Here, I change the TF(term-frequency) into tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text_positive = []\n",
    "tokenized_text_negative = []\n",
    "\n",
    "#如果直接用原来的tokenized处理，再用tfidf，效果会比较差，因为其把水词什么的去掉了。但是在这个基础上用count会比较好，比百分比要好\n",
    "# for i in positive_tokenized:\n",
    "#     tokenized_text_positive.append(' '.join(i))\n",
    "\n",
    "# for i in negative_tokenized:\n",
    "#     tokenized_text_negative.append(' '.join(i))\n",
    "\n",
    "for review in positive_review:\n",
    "    tokenized_text_positive.append(review.text)\n",
    "for review in negative_review:\n",
    "    tokenized_text_negative.append(review.text)\n",
    "    \n",
    "\n",
    "Y = np.zeros((len(positive_tokenized)+len(negative_tokenized),1))\n",
    "Y[:len(positive_tokenized)]=1\n",
    "Y[len(negative_tokenized):]=0    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffle arrays or sparse matrices in a consistent way\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.utils.shuffle.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "Count_Vectorizer = TfidfVectorizer(decode_error = 'ignore')\n",
    "data = tokenized_text_positive+tokenized_text_negative\n",
    "X = Count_Vectorizer.fit_transform(data)\n",
    "X,Y =shuffle(X,Y)\n",
    "Xtrain = X[:-100,]\n",
    "Xtest = X[-100:,]\n",
    "Ytrain = Y[:-100,]\n",
    "Ytest =Y[-100:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9447368421052632\n",
      "Test accuracy: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(Xtrain, Ytrain)\n",
    "print(\"Train accuracy:\", model.score(Xtrain, Ytrain))\n",
    "print(\"Test accuracy:\", model.score(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9447368421052632\n",
      "Test accuracy: 0.78\n"
     ]
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(Xtrain, Ytrain)\n",
    "print(\"Train accuracy:\", model.score(Xtrain, Ytrain))\n",
    "print(\"Test accuracy:\", model.score(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8468421052631578\n",
      "Test accuracy: 0.78\n"
     ]
    }
   ],
   "source": [
    "model = AdaBoostClassifier()\n",
    "model.fit(Xtrain, Ytrain)\n",
    "print(\"Train accuracy:\", model.score(Xtrain, Ytrain))\n",
    "print(\"Test accuracy:\", model.score(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try regression\n",
    "从xml里面抽取rating和text，然后用regression试试看\n",
    "\n",
    "regression 的 预测能力堪忧啊\n",
    "\n",
    "应该是特征不行吧，用词袋模型会造成过拟合？ 太稀疏了矩阵。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_review = BeautifulSoup(open('sorted_data_acl/electronics/positive.review').read())\n",
    "negative_review = BeautifulSoup(open('sorted_data_acl/electronics/negative.review').read())\n",
    "positive_rating = positive_review.findAll('rating')\n",
    "negative_rating = negative_review.findAll('rating')\n",
    "# positive_text = positive_review.findAll('review_text')\n",
    "# negative_text = negative_review.findAll('review_text')\n",
    "\n",
    "#构建rating的值\n",
    "Y = np.zeros((len(positive_tokenized)+len(negative_tokenized),1))\n",
    "i = 0\n",
    "for rating in positive_rating:\n",
    "    Y[i] = float(rating.text)\n",
    "    i+=1\n",
    "for rating in negative_rating:\n",
    "    Y[i] = float(rating.text)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "Count_Vectorizer = CountVectorizer(decode_error = 'ignore')\n",
    "data = tokenized_text_positive+tokenized_text_negative\n",
    "X = Count_Vectorizer.fit_transform(data)\n",
    "X,Y =shuffle(X,Y)\n",
    "Xtrain = X[:-100,]\n",
    "Xtest = X[-100:,]\n",
    "Ytrain = Y[:-100,]\n",
    "Ytest =Y[-100:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9947368421052631\n",
      "Test accuracy: 0.6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(Xtrain, Ytrain)\n",
    "print(\"Train accuracy:\", model.score(Xtrain, Ytrain))\n",
    "print(\"Test accuracy:\", model.score(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 4., 5.])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       ...,\n",
       "       [5.],\n",
       "       [2.],\n",
       "       [5.]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  逻辑回归多分类\n",
    "只需要输入带有分类标号的column就行\n",
    "\n",
    "class 的顺序按照 model.clasees 的顺序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 4., 5.])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.27289238e-01, 2.81981473e-02, 1.96836200e-02, 8.24828995e-01],\n",
       "       [2.00090985e-02, 4.82625838e-03, 7.72405170e-01, 2.02759474e-01],\n",
       "       [2.69972517e-04, 5.37364660e-02, 9.45175943e-01, 8.17618628e-04],\n",
       "       ...,\n",
       "       [1.79058017e-02, 1.13439081e-07, 8.83999718e-01, 9.80943666e-02],\n",
       "       [1.04367200e-01, 2.17076942e-01, 6.08335409e-01, 7.02204486e-02],\n",
       "       [1.96534583e-03, 1.91153822e-01, 2.15775832e-01, 5.91105000e-01]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9996504713485501\n",
      "Test accuracy: -0.9337260575564089\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(Xtrain, Ytrain)\n",
    "print(\"Train accuracy:\", model.score(Xtrain, Ytrain))\n",
    "print(\"Test accuracy:\", model.score(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.10082941916038546\n",
      "Test accuracy: 0.08042623704295027\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "model =AdaBoostRegressor()\n",
    "model.fit(Xtrain, Ytrain)\n",
    "print(\"Train accuracy:\", model.score(Xtrain, Ytrain))\n",
    "print(\"Test accuracy:\", model.score(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9105263157894737\n",
      "Test accuracy: 0.44\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "model =GaussianNB()\n",
    "model.fit(Xtrain.toarray(), Ytrain)\n",
    "print(\"Train accuracy:\", model.score(Xtrain.toarray(), Ytrain))\n",
    "print(\"Test accuracy:\", model.score(Xtest.toarray(), Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
