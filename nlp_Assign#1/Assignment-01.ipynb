{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson-01 Assignment - \n",
    "#### 学生姓名：  杨浩铭"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`各位同学大家好，欢迎各位开始学习我们的人工智能课程。这门课程假设大家不具备机器学习和人工智能的知识，但是希望大家具备初级的Python编程能力。根据往期同学的实际反馈，我们课程的完结之后 能力能够超过80%的计算机人工智能/深度学习方向的硕士生的能力。`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 本次作业的内容"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 复现课堂代码\n",
    "\n",
    "在本部分，你需要参照我们给大家的GitHub地址里边的课堂代码，结合课堂内容，复现内容。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 请回答以下问题\n",
    "\n",
    "回答以下问题，并将问题发送至 mqgao@kaikeba.com中：\n",
    "```\n",
    "    2.1. what do you want to acquire in this course？\n",
    "    2.2. what problems do you want to solve？\n",
    "    2.3. what’s the advantages you have to finish you goal?\n",
    "    2.4. what’s the disadvantages you need to overcome to finish you goal?\n",
    "    2.5. How will you plan to study in this course period?\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 如何提交\n",
    "代码 + 此 jupyter 相关，提交至自己的 github 中(**所以请务必把GitHub按照班主任要求录入在Trello中**)；\n",
    "第2问，请提交至mqgao@kaikeba.com邮箱。\n",
    "#### 4. 作业截止时间\n",
    "此次作业截止时间为 2019.7.6日"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. 完成以下问答和编程练习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基础理论部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. Can you come up out 3 sceneraies which use AI methods? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr><td bgcolor=\"cornsilk\"> \n",
    "Answer: \n",
    "    \n",
    "1. Self-driving car that can detect the surrsounding envrionment and adjust its velocuity based on that.\n",
    "    \n",
    "2. Voice-powered personal assistant like Siri and Alexa using machine-learning technology to get smarter and better able to predict and understand our natural-language questions and requests.\n",
    "    \n",
    "3. Cogito fuses machine learning and behavioral science to imporve customer interaction for phone professional \n",
    "    \n",
    "4. Personalisation Engine like Boxever that use AI method to create personalized customer interaction.\n",
    "</td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. How do we use Github; Why do we use Jupyter and Pycharm;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr><td bgcolor=\"cornsilk\">\n",
    "Answer: \n",
    "    \n",
    "1. Gihub can be used by installing Git and create an account on github. We can Create a repository and add new files to it. We can create branches to move back and forth between 'states' of our projects. We can make a pull request and merge a pull request to cooperate with other people to change the code. We can also ensure that the local repository and the online repository stay the same content. \n",
    "    \n",
    "    \n",
    "2. We use Jupyter to demonstrate the result of our program step by step.  It is good for teaching and sharing since the user can clear see the code combined with e it's result. Pycharm is a python IDE that is more suitable for developing.\n",
    "</td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. What's the Probability Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr><td bgcolor=\"cornsilk\">A probability model is a mathematical representation of a random phenomenon. It is defined by its sample space, events within the sample space, and probabilities associated with each event.</td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Can you came up with some sceneraies at which we could use Probability Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr><td bgcolor=\"cornsilk\">\n",
    "Answer: \n",
    "    \n",
    "1. Using probability model to evluate a basketball player's performance, such as his hit rate. \n",
    "    \n",
    "2. Using probability model in A/B testing, conducting online experiment and apply statistical test on the experiment.\n",
    "    \n",
    "3. Using probability model to evluate the performance of a machine learning algorithm--such as confusion matrix.\n",
    "</td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Why do we use probability and what's the difficult points for programming based on parsing and pattern match?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr><td style='font-size:12px'  bgcolor=\"cornsilk\">\n",
    "Answer: \n",
    "    \n",
    "1. The reason for us to use probability in natural language processing is it gives us better performance than traditional linguist method. \n",
    "    \n",
    "2. Difficult in parsing : hard to know where to parse, and what should parse , especially in chinese. \n",
    "    \n",
    "   Difficult in pattern match : It is very hard to make the pattern flexiable, such as include mulitple uncertain numebr of words and more varibales. Further, matching a reasonable response based on the input is difficult too.\n",
    "</td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. What's the Language Model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr><td bgcolor=\"cornsilk\"> \n",
    "    A statistical language model is a probability distribution over sequences of words. Given such a sequence, say of length $m$, it assigns a probability $P(w_1.....w_n)$ to the whole sequence. - wiki\n",
    "</td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Can you came up with some sceneraies at which we could use Language Model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr><td bgcolor=\"cornsilk\"> \n",
    "Voice recognition,\n",
    "machine translation,\n",
    "parsing\n",
    "</td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. What's the 1-gram language model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr><td style='font-size:12px' bgcolor=\"cornsilk\"> \n",
    "Simply put, the 1-gram lanugage model assume the words $w_i$ are independed with each other. Each word probability of showing up is not affected by others.The probability of a combination of the words or a sentence is simply multiplication of each word's probability. For example, the probability of a three-word sentence is: \n",
    "\n",
    "$$P(w_1w_2w_3)=P(w_1)P(w_2)P(w_3)$$\n",
    "</td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. What's the disadvantages and advantages of 1-gram language model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr><td style='font-size:12px' bgcolor=\"cornsilk\"> \n",
    "Advantages: very easy to calculate. It just calculate each words show-up probability and multiply them together.\n",
    "\n",
    "Disadvantages: The performance of this model is not so good and the aussmption is not convincing. In natrual language, the words in a sentence or even in a paragraph are associated with each other\n",
    "</td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. What't the 2-gram models;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr><td style='font-size:12px' bgcolor=\"cornsilk\"> \n",
    "The 2-gram model assumes the a word's show-up probability is associated with its preceding 1 word. the probability $P(w_1...w_n)$ of observing the sentence $w_1...w_n$ is $$P(w_1.....w_n) =  \\prod_{i=2}^{n}{P(w_i \\mid w_{i-1})}$$\n",
    "</td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 编程实践部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 设计你自己的句子生成器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如何生成句子是一个很经典的问题，从1940s开始，图灵提出机器智能的时候，就使用的是人类能不能流畅和计算机进行对话。和计算机对话的一个前提是，计算机能够生成语言。\n",
    "\n",
    "计算机如何能生成语言是一个经典但是又很复杂的问题。 我们课程上为大家介绍的是一种基于规则（Rule Based）的生成方法。该方法虽然提出的时间早，但是现在依然在很多地方能够大显身手。值得说明的是，现在很多很实用的算法，都是很久之前提出的，例如，二分查找提出与1940s, Dijstra算法提出于1960s 等等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在著名的电视剧，电影《西部世界》中，这些机器人们语言生成的方法就是使用的SyntaxTree生成语言的方法。\n",
    "\n",
    "> \n",
    ">\n",
    "\n",
    "![WstWorld](https://timgsa.baidu.com/timg?image&quality=80&size=b10000_10000&sec=1561818705&di=95ca9ff2ff37fcb88ae47b82c7079feb&src=http://s7.sinaimg.cn/mw690/006BKUGwzy75VK46FMi66&690)\n",
    "\n",
    "> \n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这一部分，需要各位同学首先定义自己的语言。 大家可以先想一个应用场景，然后在这个场景下，定义语法。例如：\n",
    "\n",
    "在西部世界里，一个”人类“的语言可以定义为：\n",
    "``` \n",
    "human = \"\"\"\n",
    "human = 自己 寻找 活动\n",
    "自己 = 我 | 俺 | 我们 \n",
    "寻找 = 看看 | 找找 | 想找点\n",
    "活动 = 乐子 | 玩的\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "一个“接待员”的语言可以定义为\n",
    "```\n",
    "host = \"\"\"\n",
    "host = 寒暄 报数 询问 业务相关 结尾 \n",
    "报数 = 我是 数字 号 ,\n",
    "数字 = 单个数字 | 数字 单个数字 \n",
    "单个数字 = 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 \n",
    "寒暄 = 称谓 打招呼 | 打招呼\n",
    "称谓 = 人称 ,\n",
    "人称 = 先生 | 女士 | 小朋友\n",
    "打招呼 = 你好 | 您好 \n",
    "询问 = 请问你要 | 您需要\n",
    "业务相关 = 玩玩 具体业务\n",
    "玩玩 = 耍一耍 | 玩一玩\n",
    "具体业务 = 喝酒 | 打牌 | 打猎 | 赌博\n",
    "结尾 = 吗？\"\"\"\n",
    "\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建函数（create_grammar），将为string 的语法规则变成格式化的字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_grammar(string, sep = '=', block = '|'):\n",
    "    grammar = {}\n",
    "    break_string = [s.split(sep) for s in string.split('\\n')]\n",
    "    for item in break_string:\n",
    "        if not item[0].strip():continue\n",
    "        grammar[item[0].strip()] = [i.split() for i in item[1].split(block)]\n",
    "    return grammar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建函数（generate），将输入的语法规则和初始值生成句子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "choice = random.choice\n",
    "def generate(grammar, target):\n",
    "    if target not in grammar: return target\n",
    "    expression = [generate(grammar, t) for t in choice(grammar[target])]\n",
    "    return ''.join([e for e in expression if e != 'null'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 请定义你自己的语法: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一个语法：狗狗语言翻译机\n",
    " \n",
    "应用场景：狗狗可穿戴式翻译机输出人类语言，传达狗狗的意图/或者给玩具狗增加互动性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog = '''\n",
    "dog = 自己 更新  \n",
    "自己 = 我 | 人家 | 本汪 \n",
    "更新 = 动作 | 感觉 \n",
    "动作 = 要玩 | 要出去散步 | 要吃饭 |要上厕所 | 好想你\n",
    "感觉 = 饿了 | 好害怕 | 生气了 | 好开心\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_translator = create_grammar(dog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dog': [['自己', '更新']],\n",
       " '自己': [['我'], ['人家'], ['本汪']],\n",
       " '更新': [['动作'], ['感觉']],\n",
       " '动作': [['要玩'], ['要出去散步'], ['要吃饭'], ['要上厕所'], ['好想你']],\n",
       " '感觉': [['饿了'], ['好害怕'], ['生气了'], ['好开心']]}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog_translator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 输出句子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'人家好开心'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(dog_translator,'dog')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二个语法：评论员/解说员\n",
    "\n",
    "应用场景：AI自己解说一场篮球比赛"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "commentator = '''\n",
    "解说词 = 对象 动作 结果 引用 评价  \n",
    "对象 = 科比 | 乔丹 | 纳什 | 姚明\n",
    "动作 = 突破了 |一记三分 | 一个大灌篮 | 强行突破 | 被阻拦 | 变向过人 | 犯规  \n",
    "结果 = 宾语 | 无宾语\n",
    "宾语 = 对手 | 对象 | 对方的包夹 |null\n",
    "无宾语 = 直捣黄龙 | 耀武扬威 | 十分生气 |单刀赴会 \n",
    "引用 = 去年也是如此 | 这是他的习惯 |  \n",
    "评价 = 可惜了 | 真是太棒了 | 这毫无疑问是他生涯的巅峰 | 他是一个伟大的球员\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "you_need_replace_this_with_name_you_given = '''\n",
    "# you code here\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment = create_grammar(commentator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'解说词': [['对象', '动作', '结果', '引用', '评价']],\n",
       " '对象': [['科比'], ['乔丹'], ['纳什'], ['姚明']],\n",
       " '动作': [['突破了'], ['一记三分'], ['一个大灌篮'], ['强行突破'], ['被阻拦'], ['变向过人'], ['犯规']],\n",
       " '结果': [['宾语'], ['无宾语']],\n",
       " '宾语': [['对手'], ['对象'], ['对方的包夹'], ['null']],\n",
       " '无宾语': [['直捣黄龙'], ['耀武扬威'], ['十分生气'], ['单刀赴会']],\n",
       " '引用': [['去年也是如此'], ['这是他的习惯'], []],\n",
       " '评价': [['可惜了'], ['真是太棒了'], ['这毫无疑问是他生涯的巅峰'], ['他是一个伟大的球员']]}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'姚明犯规直捣黄龙去年也是如此他是一个伟大的球员'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(comment,'解说词')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: 然后，使用自己之前定义的generate函数，使用此函数生成句子。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: 然后，定义一个函数，generate_n，将generate扩展，使其能够生成n个句子:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_n(grammar, target, num):\n",
    "    sentences = [generate(grammar,target) for i in range(num)]\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['姚明变向过人耀武扬威他是一个伟大的球员', '姚明一个大灌篮十分生气这是他的习惯他是一个伟大的球员', '科比变向过人对方的包夹这是他的习惯他是一个伟大的球员', '乔丹一记三分纳什这是他的习惯这毫无疑问是他生涯的巅峰', '纳什强行突破直捣黄龙这是他的习惯他是一个伟大的球员', '姚明突破了科比去年也是如此可惜了', '纳什犯规这是他的习惯他是一个伟大的球员', '科比强行突破单刀赴会真是太棒了', '纳什被阻拦对手去年也是如此这毫无疑问是他生涯的巅峰', '乔丹被阻拦直捣黄龙这是他的习惯真是太棒了']\n"
     ]
    }
   ],
   "source": [
    "print(generate_n(comment,'解说词',10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['人家好开心', '人家好开心', '人家好害怕', '人家好开心', '人家生气了', '我要出去散步', '本汪要玩', '人家好开心', '本汪生气了', '本汪好想你']\n"
     ]
    }
   ],
   "source": [
    "print(generate_n(dog_translator,'dog',10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 使用新数据源完成语言模型的训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按照我们上文中定义的`prob_2`函数，我们更换一个文本数据源，获得新的Language Model:\n",
    "\n",
    "1. 下载文本数据集（你可以在以下数据集中任选一个，也可以两个都使用）\n",
    "    + 可选数据集1，保险行业问询对话集： https://github.com/Computing-Intelligence/insuranceqa-corpus-zh/raw/release/corpus/pool/train.txt.gz\n",
    "    + 可选数据集2：豆瓣评论数据集：https://github.com/Computing-Intelligence/datasource/raw/master/movie_comments.csv\n",
    "2. 修改代码，获得新的**2-gram**语言模型\n",
    "    + 进行文本清洗，获得所有的纯文本\n",
    "    + 将这些文本进行切词\n",
    "    + 送入之前定义的语言模型中，判断文本的合理程度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import jieba \n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (0,4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "douban = pd.read_csv('https://raw.githubusercontent.com/Computing-Intelligence/datasource/master/movie_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>link</th>\n",
       "      <th>name</th>\n",
       "      <th>comment</th>\n",
       "      <th>star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>吴京意淫到了脑残的地步，看了恶心想吐</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>首映礼看的。太恐怖了这个电影，不讲道理的，完全就是吴京在实现他这个小粉红的英雄梦。各种装备轮...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>吴京的炒作水平不输冯小刚，但小刚至少不会用主旋律来炒作…吴京让人看了不舒服，为了主旋律而主旋...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>凭良心说，好看到不像《战狼1》的续集，完虐《湄公河行动》。</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>中二得很</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id                                        link name  \\\n",
       "0  1  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "1  2  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "2  3  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "3  4  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "4  5  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "\n",
       "                                             comment star  \n",
       "0                                 吴京意淫到了脑残的地步，看了恶心想吐    1  \n",
       "1  首映礼看的。太恐怖了这个电影，不讲道理的，完全就是吴京在实现他这个小粉红的英雄梦。各种装备轮...    2  \n",
       "2  吴京的炒作水平不输冯小刚，但小刚至少不会用主旋律来炒作…吴京让人看了不舒服，为了主旋律而主旋...    2  \n",
       "3                      凭良心说，好看到不像《战狼1》的续集，完虐《湄公河行动》。    4  \n",
       "4                                               中二得很    1  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "douban.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原来数据行数261497, 现在数据行数261497, 损失了0.0 %的数据\n"
     ]
    }
   ],
   "source": [
    "douban_clean = [''.join(re.findall('\\w+',str(i))) for i in douban.comment.tolist()]\n",
    "\n",
    "print('原来数据行数%s, 现在数据行数%s, 损失了%s %%的数据'\n",
    "      %(len(douban),len(douban_clean),((len(douban)-len(douban_clean))/len(douban)*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN =[]\n",
    "for i, line in enumerate(douban_clean):\n",
    "    TOKEN+=jieba.cut(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('的', 328262),\n",
       " ('了', 102420),\n",
       " ('是', 73106),\n",
       " ('我', 50338),\n",
       " ('都', 36255),\n",
       " ('很', 34712),\n",
       " ('看', 34022),\n",
       " ('电影', 33675),\n",
       " ('也', 32065),\n",
       " ('和', 31290)]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(TOKEN).most_common()[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN_2_gram = [''.join(TOKEN[i:i+2]) for i in range(len(TOKEN[:-2]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_2_gram = Counter(TOKEN_2_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_2(word1,word2, model = TOKEN_2_gram):\n",
    "    if (word1+word2) not in count_2_gram:\n",
    "        return 1/len(model)\n",
    "    return count_2_gram[(word1+word2)]/len(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.681051713344577e-06"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_2('烂','电影')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mult(x1,x2):\n",
    "    return x1*x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(sentence, model = TOKEN_2_gram):\n",
    "    words = list(jieba.cut(sentence))\n",
    "    totalprob =1\n",
    "    for i in range(len(words[:-1])):\n",
    "        next_ = words[i+1]\n",
    "        current = words[i]\n",
    "        totalprob*=prob_2(current,next_,model)\n",
    "    return totalprob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.094491496088627e-32"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score('我们去华盛顿公园玩把')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_reviewer(sentences, model= TOKEN_2_gram):\n",
    "    prob_list = []\n",
    "    for i in sentences:\n",
    "        print(i,'        概率为 ',score(i,model))\n",
    "        group = (i,score(i,model))\n",
    "        prob_list.append(group)\n",
    "    prob_list = sorted(prob_list,key=lambda x: x[1],reverse=True)\n",
    "#     index = np.asarray(prob_list).argmax()\n",
    "    print('最有可能合理的句子是 ', prob_list[0][0],'  概率为  ',prob_list[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "人家要出去散步         概率为  6.627076535290391e-20\n",
      "我好害怕         概率为  2.2913378691477378e-11\n",
      "本汪要玩         概率为  4.9596057773760556e-14\n",
      "人家好想你         概率为  2.2270172377815255e-07\n",
      "我饿了         概率为  1.239901444344014e-12\n",
      "本汪要上厕所         概率为  2.0985742361752905e-19\n",
      "我要出去散步         概率为  4.9596057773760556e-14\n",
      "本汪要玩         概率为  4.9596057773760556e-14\n",
      "我要出去散步         概率为  4.9596057773760556e-14\n",
      "本汪好开心         概率为  2.2270172377815255e-07\n",
      "最有可能合理的句子是  人家好想你   概率为   2.2270172377815255e-07\n"
     ]
    }
   ],
   "source": [
    "sentences = generate_n(dog_translator,'dog',10)\n",
    "sentence_reviewer(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "纳什被阻拦对手去年也是如此真是太棒了         概率为  4.960715024247132e-53\n",
      "姚明被阻拦对方的包夹这是他的习惯可惜了         概率为  1.3186191240833526e-65\n",
      "科比一记三分直捣黄龙这是他的习惯他是一个伟大的球员         概率为  1.059068509624557e-72\n",
      "纳什突破了对手去年也是如此这毫无疑问是他生涯的巅峰         概率为  3.399860820526757e-79\n",
      "乔丹一记三分对手去年也是如此可惜了         概率为  5.146741837656399e-52\n",
      "乔丹一个大灌篮姚明去年也是如此可惜了         概率为  5.295389849382942e-56\n",
      "姚明突破了他是一个伟大的球员         概率为  2.5588889146012582e-39\n",
      "纳什一个大灌篮对手去年也是如此真是太棒了         概率为  5.103990216272715e-57\n",
      "乔丹一记三分单刀赴会他是一个伟大的球员         概率为  3.6946899133720556e-50\n",
      "纳什变向过人单刀赴会去年也是如此他是一个伟大的球员         概率为  1.8628074587860786e-76\n",
      "最有可能合理的句子是  姚明突破了他是一个伟大的球员   概率为   2.5588889146012582e-39\n"
     ]
    }
   ],
   "source": [
    "sentences = generate_n(comment,'解说词',10)\n",
    "sentence_reviewer(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 获得最优质的的语言"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当我们能够生成随机的语言并且能判断之后，我们就可以生成更加合理的语言了。请定义 generate_best 函数，该函数输入一个语法 + 语言模型，能够生成**n**个句子，并能选择一个最合理的句子: \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提示，要实现这个函数，你需要Python的sorted函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_best(grammar,target,num,model=TOKEN_2_gram):\n",
    "    sentences = generate_n(grammar,target,num)\n",
    "    sentence_reviewer(sentences,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "姚明被阻拦耀武扬威这毫无疑问是他生涯的巅峰         概率为  1.8771749803147957e-60\n",
      "科比犯规这是他的习惯这毫无疑问是他生涯的巅峰         概率为  2.169869700728936e-69\n",
      "姚明一记三分耀武扬威这毫无疑问是他生涯的巅峰         概率为  1.8771749803147957e-60\n",
      "科比突破了对方的包夹去年也是如此真是太棒了         概率为  6.022861130893375e-62\n",
      "姚明突破了耀武扬威这是他的习惯可惜了         概率为  1.668214973746718e-52\n",
      "姚明变向过人单刀赴会去年也是如此真是太棒了         概率为  8.838078296576132e-59\n",
      "科比一个大灌篮乔丹去年也是如此可惜了         概率为  5.295389849382942e-56\n",
      "纳什突破了耀武扬威去年也是如此这毫无疑问是他生涯的巅峰         概率为  3.399860820526757e-79\n",
      "姚明被阻拦对方的包夹去年也是如此他是一个伟大的球员         概率为  2.64467150488268e-82\n",
      "纳什被阻拦姚明他是一个伟大的球员         概率为  3.6946899133720556e-50\n",
      "姚明犯规直捣黄龙这是他的习惯可惜了         概率为  2.3408762646811244e-47\n",
      "乔丹被阻拦对手真是太棒了         概率为  1.752943310482108e-32\n",
      "乔丹强行突破耀武扬威这是他的习惯真是太棒了         概率为  5.024743896827464e-55\n",
      "纳什一个大灌篮对手真是太棒了         概率为  1.8035717558154297e-36\n",
      "乔丹被阻拦单刀赴会真是太棒了         概率为  1.752943310482108e-32\n",
      "乔丹一个大灌篮对方的包夹这是他的习惯这毫无疑问是他生涯的巅峰         概率为  2.800681355616962e-98\n",
      "纳什变向过人真是太棒了         概率为  7.152008706767001e-30\n",
      "科比一个大灌篮十分生气这是他的习惯真是太棒了         概率为  1.1513385973569738e-65\n",
      "纳什被阻拦对方的包夹这是他的习惯真是太棒了         概率为  1.270958191887569e-66\n",
      "乔丹被阻拦真是太棒了         概率为  7.871260629434225e-26\n",
      "最有可能合理的句子是  乔丹被阻拦真是太棒了   概率为   7.871260629434225e-26\n"
     ]
    }
   ],
   "source": [
    "generate_best(comment,'解说词',20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "人家好害怕         概率为  3.9676846219008445e-13\n",
      "本汪生气了         概率为  3.4717240441632395e-13\n",
      "本汪好开心         概率为  2.2270172377815255e-07\n",
      "人家要玩         概率为  1.487881733212817e-12\n",
      "我要出去散步         概率为  4.9596057773760556e-14\n",
      "本汪好开心         概率为  2.2270172377815255e-07\n",
      "我饿了         概率为  1.239901444344014e-12\n",
      "我好想你         概率为  3.3405258566722886e-06\n",
      "人家要吃饭         概率为  1.9838423109504223e-13\n",
      "我要出去散步         概率为  4.9596057773760556e-14\n",
      "本汪要出去散步         概率为  1.104512755881732e-20\n",
      "我生气了         概率为  1.0415172132489719e-12\n",
      "人家饿了         概率为  1.239901444344014e-12\n",
      "本汪好想你         概率为  2.2270172377815255e-07\n",
      "人家好开心         概率为  2.2270172377815255e-07\n",
      "人家要玩         概率为  1.487881733212817e-12\n",
      "我好想你         概率为  3.3405258566722886e-06\n",
      "我饿了         概率为  1.239901444344014e-12\n",
      "本汪生气了         概率为  3.4717240441632395e-13\n",
      "我好害怕         概率为  2.2913378691477378e-11\n",
      "最有可能合理的句子是  我好想你   概率为   3.3405258566722886e-06\n"
     ]
    }
   ],
   "source": [
    "generate_best(dog_translator,'dog',20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 换另一个数据集语料库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/yanghaoming/Desktop/NLP/train.txt','r') as f:\n",
    "    a = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 ++$++ life-insurance ++$++ 债权人可以在死后人寿保险吗？ ++$++ Can  Creditors  Take  Life  Insurance  After  Death?\\n'"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance = [i.split('++$++')[2].strip() for i in a]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['法律要求残疾保险吗？',\n",
       " '债权人可以在死后人寿保险吗？',\n",
       " '旅行者保险有租赁保险吗？',\n",
       " '我可以开一辆没有保险的新车吗？',\n",
       " '人寿保险的现金转出价值是否应纳税？',\n",
       " '如何报告年金收入？',\n",
       " 'AAA家庭保险涵盖什么？',\n",
       " '什么是简单的退休计划？',\n",
       " '社会保险残疾保险是什么？',\n",
       " '汽车保险是否预付？']"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_clean = [''.join(re.findall('\\w+',i)) for i in insurance]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN_Insurance = []\n",
    "for i in insurance_clean:\n",
    "    TOKEN_Insurance += jieba.cut(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN_2_Insurance = [''.join(TOKEN_Insurance[i:i+2])for i in range(len(TOKEN_Insurance[:-1]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['法律要求', '要求残疾', '残疾保险', '保险吗', '吗债权人', '债权人可以', '可以在', '在死', '死后', '后人寿保险']"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKEN_2_Insurance[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "科比一个大灌篮直捣黄龙这是他的习惯可惜了         概率为  5.363738432252963e-58\n",
      "纳什犯规对方的包夹这是他的习惯可惜了         概率为  5.921009957681842e-59\n",
      "乔丹变向过人纳什他是一个伟大的球员         概率为  6.58251050026968e-56\n",
      "姚明犯规单刀赴会去年也是如此他是一个伟大的球员         概率为  4.6949484051825704e-64\n",
      "乔丹突破了直捣黄龙这是他的习惯真是太棒了         概率为  1.6079180469847884e-53\n",
      "姚明一记三分直捣黄龙这是他的习惯这毫无疑问是他生涯的巅峰         概率为  1.0761698303888486e-82\n",
      "纳什一个大灌篮十分生气这是他的习惯他是一个伟大的球员         概率为  2.426683782124602e-83\n",
      "科比一个大灌篮对手去年也是如此真是太棒了         概率为  5.103990216272715e-57\n",
      "姚明犯规姚明这是他的习惯可惜了         概率为  2.3408762646811244e-47\n",
      "乔丹变向过人对手他是一个伟大的球员         概率为  6.58251050026968e-56\n",
      "乔丹被阻拦真是太棒了         概率为  7.871260629434225e-26\n",
      "纳什一个大灌篮对手这是他的习惯他是一个伟大的球员         概率为  1.0896564880395705e-76\n",
      "科比一个大灌篮耀武扬威他是一个伟大的球员         概率为  3.8013998139057397e-54\n",
      "姚明变向过人十分生气他是一个伟大的球员         概率为  7.329682175989236e-62\n",
      "纳什被阻拦去年也是如此这毫无疑问是他生涯的巅峰         概率为  4.770760137775102e-74\n",
      "姚明变向过人对手这是他的习惯这毫无疑问是他生涯的巅峰         概率为  1.9173190104451086e-88\n",
      "纳什强行突破单刀赴会这毫无疑问是他生涯的巅峰         概率为  1.8771749803147957e-60\n",
      "科比强行突破耀武扬威这是他的习惯这毫无疑问是他生涯的巅峰         概率为  1.0761698303888486e-82\n",
      "乔丹变向过人直捣黄龙去年也是如此可惜了         概率为  9.169506232697736e-58\n",
      "姚明强行突破真是太棒了         概率为  7.871260629434225e-26\n",
      "最有可能合理的句子是  乔丹被阻拦真是太棒了   概率为   9.451641506659243e-19\n"
     ]
    }
   ],
   "source": [
    "generate_best(comment,'解说词',20,model = TOKEN_2_Insurance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我好害怕         概率为  2.2913378691477378e-11\n",
      "人家饿了         概率为  1.239901444344014e-12\n",
      "本汪好害怕         概率为  4.9596057773760556e-14\n",
      "人家饿了         概率为  1.239901444344014e-12\n",
      "人家好害怕         概率为  3.9676846219008445e-13\n",
      "人家要玩         概率为  1.487881733212817e-12\n",
      "本汪生气了         概率为  3.4717240441632395e-13\n",
      "本汪好害怕         概率为  4.9596057773760556e-14\n",
      "我好害怕         概率为  2.2913378691477378e-11\n",
      "我要出去散步         概率为  4.9596057773760556e-14\n",
      "本汪生气了         概率为  3.4717240441632395e-13\n",
      "我生气了         概率为  1.0415172132489719e-12\n",
      "本汪饿了         概率为  4.9596057773760556e-14\n",
      "本汪要玩         概率为  4.9596057773760556e-14\n",
      "我饿了         概率为  1.239901444344014e-12\n",
      "人家好害怕         概率为  3.9676846219008445e-13\n",
      "人家饿了         概率为  1.239901444344014e-12\n",
      "我生气了         概率为  1.0415172132489719e-12\n",
      "本汪要上厕所         概率为  2.0985742361752905e-19\n",
      "我要出去散步         概率为  4.9596057773760556e-14\n",
      "最有可能合理的句子是  我好害怕   概率为   7.940001908350241e-08\n"
     ]
    }
   ],
   "source": [
    "generate_best(dog_translator,'dog',20, model = TOKEN_2_Insurance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "好了，现在我们实现了自己的第一个AI模型，这个模型能够生成比较接近于人类的语言。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: 这个模型有什么问题？ 你准备如何提升？ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr><td style='font-size:12px' bgcolor=\"cornsilk\"> \n",
    " 问题：\n",
    "    \n",
    "1. 语料库对应不上。所用的语料库是和电影和保险相关的，但是输入的语言和这两个领域差距较大，模型输出的结果不一定准确\n",
    "    \n",
    "2. 用的是2-gram language model， 但其实词的出现不仅仅只和前一个词有关系，这样的假设也会降低模型准确性\n",
    "\n",
    "3. 模型所运用来判断句子可能性的原理是将相邻的两个词的概率相乘，这其中没有考虑标点符号所造成的断点，比如“下雨天，天留客，天留，我不留” 和“下雨天，天留客，天留我不？留！” 这里两个句子经过标点符号的处理，都说得通，但模型判断可能性会有差别。\n",
    "\n",
    "4. 所用的输入语句不含标点符号。\n",
    "\n",
    "改进方案：\n",
    "    \n",
    "1. 使用适合主题的语料库。比如“影评”的输入就用“影评的语料库”\n",
    "    \n",
    "2. 可以采用3-gram model 来提升性能\n",
    "\n",
    "3. 还不知道\n",
    "\n",
    "4. 还不知道\n",
    "\n",
    "\n",
    "</td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 以下内容为可选部分，对于绝大多数同学，能完成以上的项目已经很优秀了，下边的内容如果你还有精力可以试试，但不是必须的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. (Optional) 完成基于Pattern Match的语句问答\n",
    "> 我们的GitHub仓库中，有一个assignment-01-optional-pattern-match，这个难度较大，感兴趣的同学可以挑战一下。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 5. (Optional) 完成阿兰图灵机器智能原始论文的阅读\n",
    "1. 请阅读阿兰图灵关于机器智能的原始论文：https://github.com/Computing-Intelligence/References/blob/master/AI%20%26%20Machine%20Learning/Computer%20Machinery%20and%20Intelligence.pdf \n",
    "2. 并按照GitHub仓库中的论文阅读模板，填写完毕后发送给我: mqgao@kaikeba.com 谢谢"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各位同学，我们已经完成了自己的第一个AI模型，大家对人工智能可能已经有了一些感觉，人工智能的核心就是，我们如何设计一个模型、程序，在外部的输入变化的时候，我们的程序不变，依然能够解决问题。人工智能是一个很大的领域，目前大家所熟知的深度学习只是其中一小部分，之后也肯定会有更多的方法提出来，但是大家知道人工智能的目标，就知道了之后进步的方向。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后，希望大家对AI不要有恐惧感，这个并不难，大家加油！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1561828422005&di=48d19c16afb6acc9180183a6116088ac&imgtype=0&src=http%3A%2F%2Fb-ssl.duitang.com%2Fuploads%2Fitem%2F201807%2F28%2F20180728150843_BECNF.thumb.224_0.jpeg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
